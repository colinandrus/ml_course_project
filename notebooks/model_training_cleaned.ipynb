{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import dependencies \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, log_loss, \\\n",
    "    precision_score, recall_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline \n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define folder where data resides \n",
    "DATAFOLDER = \"~/Documents/data-science-coursework/nyu-ml/project/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to load data \n",
    "def load_data(filename, root_path=DATAFOLDER):\n",
    "    csv_path = os.path.join(root_path, filename)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 242466 entries, 4657002.0 to 5021568.0\n",
      "Columns: 231 entries, idncase to last_10_appeal_grant_by_judge_nat\n",
      "dtypes: bool(1), float64(96), int64(41), object(93)\n",
      "memory usage: 427.6+ MB\n",
      "None\n",
      "['idncase', 'idnproceeding', 'nat', 'case_type', 'c_asy_type', 'base_city_code', 'hearing_loc_code', 'dec_type', 'dec_code', 'other_comp', 'attorney_flag', 'ij_code', 'tracid', 'case_type_string', '_mcase', 'original_dec_type_string', '_mdectype', 'outcome_recorded_in_field', 'original_dec_string', '_mdecproceeddec', '_mdecproceedoth', 'nat_string', '_mnat', 'base_city_street', 'base_city_string', 'base_city_state', 'base_city_zip5', 'base_city_zip4', 'base_city_phone', '_mbasecity', 'hearing_loc_string1', 'hearing_loc_string2', 'hearing_loc_street', 'hearing_loc_city', 'hearing_loc_state', 'hearing_loc_zip5', 'hearing_loc_phone', '_mhearingloc', 'judge_name_caps', '_mlookupijcode', 'idncode', 'idnproceedingappln', 'appl_code', 'appl_dec', '_mappln', 'application_type_string', '_mapplcode', 'application_dec_string', '_mappldec', 'cityid', 'judgeid', 'natid', 'comp_year', 'comp_month', 'comp_day', 'comp_date', 'osc_year', 'osc_month', 'osc_day', 'osc_date', 'input_year', 'input_month', 'input_day', 'input_date', 'appl_year', 'appl_month', 'appl_day', 'appl_recd_date', 'strdescription', 'torture', 'asylum', 'waiver', 'child', 'voluntary', 'original_granted', 'deny', 'abandoned', 'withdrawn', 'venue_change', 'deport', 'relief_granted', 'remove', 'terminated', 'voluntary_departure', 'oral', 'written', 'deport_form', 'voluntary_form', 'deportation_proceeding', 'exclusion_proceeding', 'removal_proceeding', 'asylum_only_proceeding', 'withholding_only_proceeding', 'lawyer', 'defensive', 'affirmative', 'mistakegrantdeny', 'idnschedule', 'generation', 'sub_generation', 'rec_type', 'alien_atty_code', 'lang', 'interpreter_code', 'input_time', 'update_date', 'update_time', 'assignment_path', 'continue_flag', 'cal_type', 'adj_date', 'adj_time_start', 'adj_time_stop', 'adj_rsn', 'adj_medium', 'adj_msg', 'adj_elap_days', 'id_1', 'lngsessnid', 'schedule_type', 'notice_code', 'datbatchmodified', 'strcreatedby', 'strmodifiedby', 'blnclockoverride', 'eoirattorneyid', 'idncasedups', 'adj_rsn_string', 'adj_requested_by', 'adj_clock_status', '_madj', 'cal_type_string', '_mcaltype', 'notice_code_string', '_mnotice', 'schedule_type_string', '_mschedcodes', 'adj_completion_prior_to_hearing', 'adj_case_conversion', 'adj_alien_to_seek_representation', 'adj_merits_hearing', 'adj_to_file', 'adj_preparation', 'adj_consolidation_family', 'government_requested', 'alien_requested', 'either_requested', 'clock_stopped', 'clock_running', 'clock_end', 'individual_cal', 'multiple_cal', 'deportation_notice', 'exclusion_notice', 'removal_notice', 'asylum_only_notice', 'withholding_only_notice', 'custody_notice', 'family_notice', 'initial_notice', 'individual_sched', 'multiple_sched', 'unknown_sched', 'adj_date_stamp', 'adj_year', 'adj_month', 'adj_day', 'adj_input_year', 'adj_input_month', 'adj_input_day', 'adj_input_date', 'adj_osc_year', 'adj_osc_month', 'adj_osc_day', 'adj_osc_date', 'eoirattyid', 'alienattyid', 'langid', 'hearingid', 'basecityid', 'last_hearing_on_comp_date', 'idnProceeding', 'strAppealCategory', 'strAppealType', 'datAppealFiled', 'strFiledBy', 'datAttorneyE27', 'datBIADecision', 'strBIADecision', 'strBIADecisionType', 'strCaseType', 'strLang', 'strNat', 'strProceedingIHP', 'strCustody', 'strProbono', 'strAppealCategoryDesc', 'strAppealTypeDesc', 'strBIADecisionDesc', 'strBIADecisionTypeDesc', 'Male_judge', 'Year_Appointed_SLR', 'Year_College_SLR', 'Year_Law_school_SLR', 'Government_Years_SLR', 'Govt_nonINS_SLR', 'INS_Years_SLR', 'Military_Years_SLR', 'NGO_Years_SLR', 'Privateprac_Years_SLR', 'Academia_Years_SLR', 'judge_missing_bio', 'ij_code_nat', 'datAppealFiled_dt', 'datAppealFiled_year', 'datAppealFiled_month', 'datAppealFiled_year_month', 'datBIADecision_dt', 'datBIADecision_year', 'datBIADecision_month', 'datBIADecision_year_month', 'appealed', 'granted', 'ij_code_grouped', 'nat_grouped', 'ij_code_nat_grouped', 'hearing_loc_code_grouped', 'years_since_judge_appointment', 'years_since_law_school', 'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat']\n"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "df = load_data(filename=\"data_for_model/appeals_data_final.csv\", root_path=DATAFOLDER)\n",
    "df.set_index('idnAppeal', inplace=True) \n",
    "print(df.info()) \n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute missing data\n",
    "\n",
    "def impute_columns_udf(col, imputation_type): \n",
    "    \"\"\" \n",
    "    UDF to specify imputation method for a given variable. \n",
    "    col is the pd.Series for which you want to impute, imputation_type should be chosen from \n",
    "    ['mode', 'mean', 'median', 'zero', 'none'] \n",
    "    \"\"\" \n",
    "    if imputation_type == 'mode':\n",
    "        val = col.mode()[0]\n",
    "        return col.fillna(val)\n",
    "    \n",
    "    elif imputation_type == 'mean': \n",
    "        val = col.mean() \n",
    "        return col.fillna(val)\n",
    "    \n",
    "    elif imputation_type == 'median': \n",
    "        val = col.median() \n",
    "        return col.fillna(val)\n",
    "    \n",
    "    elif imputation_type == 'zero': \n",
    "        return col.fillna(0)\n",
    "    \n",
    "    elif imputation_type == 'none':\n",
    "        return col.fillna('None')\n",
    "    \n",
    "    else: \n",
    "        raise ValueError('imputation_type argument not valid')\n",
    "\n",
    "class ImputeMissingData(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Pipeline step that impute missing values, given impute methods specified. \n",
    "        Note that numerical features with NaN's and no impute methods will raise an error, \n",
    "        categorical features on the other hand will be filled with 'None' by default unless specified otherwise.\n",
    "    \"\"\"\n",
    "    def __init__(self, impute_methods, num_features, cat_features): \n",
    "        self.impute_methods = impute_methods\n",
    "        self.num_features = num_features\n",
    "        self.cat_features = cat_features\n",
    "    \n",
    "    def fit(self, X, y=None): \n",
    "        return self \n",
    "    \n",
    "    def transform(self, input_data): \n",
    "        output_data = input_data.copy() \n",
    "\n",
    "        # check which features have missing values but imputation methods not specified \n",
    "        features_nulls = output_data.isnull().sum() \n",
    "        features_nulls = features_nulls[features_nulls > 0].index.tolist() \n",
    "        features_need_impute = [f for f in features_nulls if f not in self.impute_methods.keys()]\n",
    "        num_features_need_impute = [f for f in features_need_impute if f in self.num_features]\n",
    "        cat_features_need_impute = [f for f in features_need_impute if f in self.cat_features]\n",
    "        \n",
    "        # raise exception for numerical features with missing values and no imputation method specified \n",
    "        if num_features_need_impute: \n",
    "            raise Exception(\"\"\"These numerical features have missing values: {}. \n",
    "            Please specify their impute methods.\"\"\".format(num_features_need_impute)) \n",
    "        \n",
    "        # set imputation method as 'none' for cat features with missing values with no imputation method specified \n",
    "        if cat_features_need_impute: \n",
    "            for cat_f in cat_features_need_impute: \n",
    "                self.impute_methods[cat_f] = 'none'\n",
    "            print(\"\"\"{} have missing values with no imputation method specified. \n",
    "            By default, they have been filled with 'None'.\"\"\".format(cat_features_need_impute)) \n",
    "                \n",
    "        # apply imputations \n",
    "        for col, imp_method in self.impute_methods.items(): \n",
    "            output_data[col] = impute_columns_udf(output_data[col], imp_method)\n",
    "            \n",
    "        return output_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert data types\n",
    "class ConvertDataTypes(BaseEstimator, TransformerMixin): \n",
    "    \"\"\" Coerce data types to specifications defined by CAT_FEATURES and NUM_FEATURES \"\"\"\n",
    "    def __init__(self, num_features, cat_features): \n",
    "        self.num_features = num_features \n",
    "        self.cat_features = cat_features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, input_data): \n",
    "        output_data = input_data.copy() \n",
    "        output_data[self.num_features] = output_data[self.num_features].astype(float)\n",
    "        output_data[self.cat_features] = output_data[self.cat_features].astype(str)\n",
    "        return output_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dummify data \n",
    "\n",
    "class Dummify(BaseEstimator, TransformerMixin): \n",
    "    \"\"\" Pipeline step that dummifies all categorical variables \"\"\"\n",
    "    def __init__(self, cat_feature_values): \n",
    "        self.cat_feature_values = cat_feature_values\n",
    "    \n",
    "    def fit(self, X, y=None): \n",
    "        return self\n",
    "    \n",
    "    def transform(self, input_data):\n",
    "        output_data = input_data.copy()\n",
    "        # specify values categorical features can take on, to ensure train/test DF have same cols \n",
    "        cat_features = self.cat_feature_values.keys()\n",
    "        for col in cat_features: \n",
    "            output_data[col] = pd.Categorical(output_data[col], categories=self.cat_feature_values[col])        \n",
    "        output_data = pd.get_dummies(output_data, columns=cat_features, prefix_sep=':::')\n",
    "        return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to subset and transform data (impute, convert, dummify)\n",
    "\n",
    "def transform_features(data, df, cat_features, num_features, impute_methods): \n",
    "    \"\"\" Impute, convert and dummify features \n",
    "        TODO: save cat_feature_values to pickle so that we don't have to read df \n",
    "    \"\"\"  \n",
    "    \n",
    "    # subsets features we are interested in \n",
    "    cat_feature_values = dict([(f, [str(x) for x in df[f].dropna().unique().tolist()]) for f in cat_features])\n",
    "    data = data[cat_features + num_features].copy() \n",
    "\n",
    "    # make pipeline \n",
    "    data_pipeline = Pipeline([\n",
    "        ('impute', ImputeMissingData(impute_methods, num_features, cat_features)),         \n",
    "        ('convert_dtypes', ConvertDataTypes(num_features, cat_features)), \n",
    "        ('dummify', Dummify(cat_feature_values))\n",
    "    ])\n",
    "    \n",
    "    # run pipeline \n",
    "    X = data_pipeline.fit_transform(data)\n",
    "    \n",
    "    return X\n",
    "\n",
    "# method to split train-test and transform features \n",
    "\n",
    "def get_model_data(df, label, cat_features, num_features, impute_methods, test_size=0.2, print_summary=False): \n",
    "    \"\"\" Subsets features used, splits into train-test, and transforms features \"\"\"\n",
    "    \n",
    "    # subsets features we are interested in \n",
    "    data = df[cat_features + num_features + [label]].copy() \n",
    "    \n",
    "    # train test split \n",
    "    X, y = data.drop(label, axis=1).copy(), data[label].copy() \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=44)\n",
    "\n",
    "    # transform features\n",
    "    X_train = transform_features(x_train, df, cat_features, num_features, impute_methods)\n",
    "    X_test = transform_features(x_test, df, cat_features, num_features, impute_methods)\n",
    "\n",
    "    if print_summary:\n",
    "        print(\"Training Data: {} | Test Data: {}\".format(X_train.shape, X_test.shape)) \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # method to subset data for training model - DEPRECATE - doesn't work on pure prediction data \n",
    "# def get_model_data(df, label, cat_features, num_features, impute_methods, test_size=0.2, print_summary=False): \n",
    "#     \"\"\" Subsets variables used for model, runs it through pipeline to output data for model \n",
    "#         Set test_size = 0 if generating data only for prediction \n",
    "#         (TODO: IF HAVE TIME SPLIT INTO SEPARATE FUNCTION)\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # subsets features we are interested in \n",
    "#     cat_feature_values = dict([(f, [str(x) for x in df[f].dropna().unique().tolist()]) for f in cat_features]) # do EDA and limit to smaller list\n",
    "#     data = df[cat_features + num_features + [label]].copy() \n",
    "    \n",
    "#     # train test split \n",
    "#     X, y = data.drop(label, axis=1).copy(), data[label].copy() \n",
    "#     x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=44)\n",
    "    \n",
    "#     # make pipeline \n",
    "#     data_pipeline = Pipeline([\n",
    "#         ('impute', ImputeMissingData(impute_methods, num_features, cat_features)),         \n",
    "#         ('convert_dtypes', ConvertDataTypes(num_features, cat_features)), \n",
    "#         ('dummify', Dummify(cat_feature_values))\n",
    "#     ])\n",
    "    \n",
    "#     # run pipeline \n",
    "#     X_train = data_pipeline.fit_transform(x_train)\n",
    "#     X_test = data_pipeline.transform(x_test)\n",
    "#     if print_summary:\n",
    "#         print(\"Training Data: {} | Test Data: {}\".format(X_train.shape, X_test.shape)) \n",
    "    \n",
    "#     return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to return model evaluation metrics \n",
    "def evaluate_model(truth, pred): \n",
    "    \"\"\" Takes in arrays of truth and pred y values and return accuracy, logloss, roc_auc, and plot ROC \"\"\" \n",
    "    accuracy = accuracy_score(truth, (pred>0.5).astype(int))\n",
    "    logloss = log_loss(truth, pred)\n",
    "    fpr, tpr, thresholds = roc_curve(truth, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    precision = precision_score(truth, (pred>0.5).astype(int))\n",
    "    recall = recall_score(truth, (pred>0.5).astype(int))\n",
    "    metrics = {'Accuracy': accuracy, 'ROC AUC': roc_auc, 'Log Loss': logloss, \n",
    "               'Precision': precision, 'Recall': recall}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to plot ROC \n",
    "\n",
    "def plot_roc(truth, pred, model_name=None, title=None): \n",
    "    \"\"\" Takes in arrays of truth classes and pred probs to plot ROC curve \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(truth, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    if model_name is not None: \n",
    "        plt.plot(fpr, tpr, label= '{0} (AUC = {1:.3f})'.format(model_name, roc_auc)) \n",
    "    else: \n",
    "        plt.plot(fpr, tpr, label= 'AUC:{0:.3f}'.format(roc_auc)) \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    if title is not None: \n",
    "        plt.title(title)\n",
    "    else: \n",
    "        plt.title('ROC')\n",
    "    plt.legend(loc=\"lower right\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to plot precision-recall curve \n",
    "\n",
    "def plot_precision_recall(truth, pred, model_name=None, title=None): \n",
    "    \"\"\" Takes in arrays of truth classes and pred probs to plot precision-recall curve\n",
    "        Code borrowed from http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "    \"\"\"    \n",
    "    precision, recall, _ = precision_recall_curve(truth, pred)\n",
    "    average_precision = average_precision_score(truth, pred)\n",
    "    plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2, color='b', \n",
    "                     label='Avg Precision:{0:.3f}'.format(average_precision))\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    if title is not None: \n",
    "        plt.title(title)\n",
    "    else: \n",
    "        plt.title('Precision-Recall curve') \n",
    "    plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to train a model, output results, and plot AUC \n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, \n",
    "                print_metrics=True, print_charts=False, sample_weight=None):\n",
    "    if sample_weight is not None: \n",
    "        model.fit(X_train, y_train.values.ravel(), sample_weight)\n",
    "    else: \n",
    "        model.fit(X_train, y_train.values.ravel())\n",
    "    truth = y_test.values.ravel()\n",
    "    pred = model.predict_proba(X_test)[:,1]\n",
    "    metrics = evaluate_model(truth, pred)\n",
    "    try: \n",
    "        fi, cfi = get_feature_importances(model, X_train)\n",
    "    except AttributeError: \n",
    "        fi, cfi = None, None \n",
    "    \n",
    "    if print_metrics: \n",
    "        print(metrics)\n",
    "    if print_charts: \n",
    "        plot_metrics(truth, pred)\n",
    "    return model, metrics, fi, cfi, truth, pred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to train a model, output results, and plot AUC (WITH FEATURE SELECTION)\n",
    "\n",
    "# def train_model_with_feature_selection(model, X_train, y_train, X_test, y_test, \n",
    "#                                        print_metrics=True, print_charts=False, sample_weight=None,\n",
    "#                                        feature_selection_threshold=\"0.25*mean\"):\n",
    "    \n",
    "#     print(\"Original Features: {}\".format(X_train.shape[1]))\n",
    "    \n",
    "#     # perform feature selection \n",
    "#     sfm = SelectFromModel(model, threshold=feature_selection_threshold)\n",
    "#     sfm.fit(X_train, y_train)\n",
    "#     X_train = sfm.transform(X_train)\n",
    "#     X_test = sfm.transform(X_test)\n",
    "#     print(\"New Features: {}\".format(X_train.shape[1]))\n",
    "    \n",
    "#     if sample_weight is not None: \n",
    "#         model.fit(X_train, y_train.values.ravel(), sample_weight)\n",
    "#     else: \n",
    "#         model.fit(X_train, y_train.values.ravel())\n",
    "#     truth = y_test.values.ravel()\n",
    "#     pred = model.predict_proba(X_test)[:,1]\n",
    "#     metrics = evaluate_model(truth, pred)\n",
    "# #    fi, cfi = get_feature_importances(model, X_train)\n",
    "    \n",
    "#     if print_metrics: \n",
    "#         print(metrics)\n",
    "#     if print_charts: \n",
    "#         plot_metrics(truth, pred)\n",
    "#     return model, metrics, truth, pred  \n",
    "# #    return model, metrics, fi, cfi, truth, pred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to plot ROC and Precision-Recall\n",
    "\n",
    "def plot_metrics(truth, pred): \n",
    "    \"\"\" Plots ROC and Precision-Recall curves \"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plot_roc(truth, pred)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_precision_recall(truth, pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to get feature importances \n",
    "\n",
    "def get_feature_importances(model, X_train):\n",
    "    \n",
    "    \"\"\" Takes model and train data as inputs, outputs regular and collapsed feature importances \"\"\"\n",
    "    \n",
    "    # get 'regular' feature importances \n",
    "    fi = pd.Series(data=model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "    \n",
    "    # get 'collapsed' feature importances (dummy variables of parent feature aggregated as one)\n",
    "    cfi = pd.DataFrame(fi).reset_index().rename(columns={'index': 'feature', 0: 'importance'})\n",
    "    cfi['parent_feature'] = cfi['feature'].apply(lambda x: x.split(':::')[0])\n",
    "    cfi = cfi.groupby('parent_feature')['importance'].sum().sort_values(ascending=False) \n",
    "    \n",
    "    return fi, cfi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Different Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Variable  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (193972, 217) | Test Data: (48494, 217)\n",
      "{'Recall': 0.090585920142195131, 'Log Loss': 0.59390245578952106, 'Precision': 0.57913961038961037, 'ROC AUC': 0.66562832386584836, 'Accuracy': 0.68319792139233715}\n"
     ]
    }
   ],
   "source": [
    "# nationality only \n",
    "CAT_FEATURES = ['nat_string']\n",
    "NUM_FEATURES = []\n",
    "IMPUTE_METHODS = {'nat_string': 'none'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS, \n",
    "                                                  print_summary=True) \n",
    "model, metrics, fi, cfi, _, _  = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                             print_metrics=True, print_charts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (193972, 421) | Test Data: (48494, 421)\n",
      "{'Recall': 0.064241731733638036, 'Log Loss': 0.60965700167868064, 'Precision': 0.50398406374501992, 'ROC AUC': 0.62538189457937787, 'Accuracy': 0.67548562708788717}\n"
     ]
    }
   ],
   "source": [
    "# judge only \n",
    "CAT_FEATURES = ['ij_code']\n",
    "NUM_FEATURES = []\n",
    "IMPUTE_METHODS = {}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS,\n",
    "                                                  print_summary=True) \n",
    "model, metrics, fi, cfi, _, _ = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                            print_metrics=True, print_charts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Recall': 0.034850504665777944, 'Log Loss': 0.61956671125385254, 'Precision': 0.50880444856348472, 'ROC AUC': 0.58836151530192948, 'Accuracy': 0.67554749041118489}\n"
     ]
    }
   ],
   "source": [
    "# appeal year only\n",
    "CAT_FEATURES = []\n",
    "NUM_FEATURES = ['datAppealFiled_year']\n",
    "IMPUTE_METHODS = {}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "model, metrics, fi, cfi, _, _ = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                            print_metrics=True, print_charts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nationality + judge \n",
    "CAT_FEATURES = ['nat_string', 'ij_code']\n",
    "NUM_FEATURES = []\n",
    "IMPUTE_METHODS = {'nat_string': 'none'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "model, metrics, fi, cfi, _, _ = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                            print_metrics=True, print_charts=False)\n",
    "print(cfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nationality + judge (grouped) - yields better AUC, will use grouped from here \n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped']\n",
    "NUM_FEATURES = []\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "model, metrics, fi, cfi, _, _ = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                            print_metrics=True, print_charts=False)\n",
    "print(cfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nationality + appeal year \n",
    "CAT_FEATURES = ['nat_grouped']\n",
    "NUM_FEATURES = ['datAppealFiled_year']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "model, metrics, fi, cfi, _, _ = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                            print_metrics=True, print_charts=False)\n",
    "print(cfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# judge + appeal year \n",
    "CAT_FEATURES = ['ij_code_grouped']\n",
    "NUM_FEATURES = ['datAppealFiled_year']\n",
    "IMPUTE_METHODS = {}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "model, metrics, fi, cfi, _, _ = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                            print_metrics=True, print_charts=False)\n",
    "print(cfi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Variables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nationality + judge + appeal year \n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped']\n",
    "NUM_FEATURES = ['datAppealFiled_year']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "model, metrics, fi, cfi, _, _ = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                            print_metrics=True, print_charts=True)\n",
    "print(cfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# case type + custody + probono + lawyer + defensive/affirmative + oral/written\n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "model, metrics, fi, cfi, _, _ = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                            print_metrics=True, print_charts=True)\n",
    "print(cfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# + comp/osc/input years \n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "model, metrics, fi, cfi, _, _ = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                            print_metrics=True, print_charts=True)\n",
    "print(cfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# + original proceeding decisions  \n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "model, metrics, fi, cfi, _, _ = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                            print_metrics=True, print_charts=True)\n",
    "print(cfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# + last 10 decisions by judge, judge+nationality (improves AUC by 0.0052, keep)\n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year', \n",
    "                'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero',\n",
    "                  'last_10_appeal_grant_by_judge': 'median', 'last_10_appeal_grant_by_judge_nat': 'median'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "model, metrics, fi, cfi, _, _ = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                            print_metrics=True, print_charts=True)\n",
    "print(cfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# + judge experience --> AUC slightly worse, exclude \n",
    "\n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year', \n",
    "                'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat', \n",
    "                'years_since_judge_appointment', 'years_since_law_school']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero',\n",
    "                  'last_10_appeal_grant_by_judge': 'median', 'last_10_appeal_grant_by_judge_nat': 'median'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "model, metrics, fi, cfi, _, _ = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                            print_metrics=True, print_charts=True)\n",
    "print(cfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# best with more trees \n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year', \n",
    "                'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero',\n",
    "                  'last_10_appeal_grant_by_judge': 'median', 'last_10_appeal_grant_by_judge_nat': 'median',\n",
    "                  'original_dec_type_string': 'none', 'original_dec_string': 'none'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=100, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "rf_model, rf_metrics, rf_fi, rf_cfi, rf_truth, rf_pred = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                                                     print_metrics=True, print_charts=True)\n",
    "print(cfi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Different Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for lr we dummify \"numerical variables\" so we don't assume any linear or monotonic relationship \n",
    "# between the numerical variable and log odds \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string', \n",
    "                'datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year', \n",
    "                'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat']\n",
    "NUM_FEATURES = []\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero',\n",
    "                  'last_10_appeal_grant_by_judge': 'median', 'last_10_appeal_grant_by_judge_nat': 'median',\n",
    "                  'original_dec_type_string': 'none', 'original_dec_string': 'none'}\n",
    "MODEL = (LogisticRegression(penalty='l2', C=1, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "lr_model, lr_metrics, lr_fi, lr_cfi, lr_truth, lr_pred = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                                                     print_metrics=True, print_charts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year', \n",
    "                'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero',\n",
    "                  'last_10_appeal_grant_by_judge': 'median', 'last_10_appeal_grant_by_judge_nat': 'median',\n",
    "                  'original_dec_type_string': 'none', 'original_dec_string': 'none'}\n",
    "MODEL = (GradientBoostingClassifier(loss='deviance', learning_rate=.1, n_estimators=100, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "gb_model, gb_metrics, gb_fi, gb_cfi, gb_truth, gb_pred = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                                                     print_metrics=True, print_charts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year', \n",
    "                'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero',\n",
    "                  'last_10_appeal_grant_by_judge': 'median', 'last_10_appeal_grant_by_judge_nat': 'median',\n",
    "                  'original_dec_type_string': 'none', 'original_dec_string': 'none'}\n",
    "MODEL = (XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, seed=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "xgb_model, xgb_metrics, xgb_fi, xgb_cfi, xgb_truth, xgb_pred = train_model(MODEL, X_train, y_train, X_test, y_test, \n",
    "                                                                           print_metrics=True, print_charts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm Comparison (out-of-the-box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo_comparison = {'Random Forest': rf_metrics, \n",
    "                   'Logistic Regression': lr_metrics, \n",
    "                   'Gradient Boosting': gb_metrics, \n",
    "                   'XGBoost': xgb_metrics}\n",
    "\n",
    "pd.DataFrame.from_dict(algo_comparison, orient='index').sort_values(by='ROC AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot all ROC in a single chart \n",
    "plot_roc(rf_truth, rf_pred, 'Random Forest')\n",
    "plot_roc(xgb_truth, xgb_pred, 'XGBoost')\n",
    "plot_roc(gb_truth, gb_pred, 'Gradient Boosting')\n",
    "plot_roc(lr_truth, lr_pred, 'Logistic Regression')\n",
    "plt.title('Model Comparison by ROC AUC'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Random Forest outperforms other algorithms significantly in accuracy and ROC AUC out-of-the-box, we will move forward with Random Forest and tune it to get our best model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define search scope \n",
    "max_features = ['sqrt', 'log2']\n",
    "max_depth = list(np.arange(20, 200, 20))\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# construct param grid \n",
    "param_grid = {'max_features': max_features, 'max_depth': max_depth, \n",
    "              'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "# run randomized search cv \n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year', \n",
    "                'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero',\n",
    "                  'last_10_appeal_grant_by_judge': 'median', 'last_10_appeal_grant_by_judge_nat': 'median',\n",
    "                  'original_dec_type_string': 'none', 'original_dec_string': 'none'}\n",
    "X_train, _, y_train, _ = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                        num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "rf_clf = RandomForestClassifier(n_estimators=20, random_state=44)\n",
    "rf_gridsearch = GridSearchCV(rf_clf, param_grid, scoring=['roc_auc', 'accuracy', 'neg_log_loss'], refit='roc_auc')\n",
    "rf_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_search_cv(cv_object): \n",
    "    \"\"\" Print results for randomized search cv \"\"\"\n",
    "    rename_cols = {'param_max_depth': 'max_depth', \n",
    "                   'param_max_features': 'max_features', \n",
    "                   'param_min_samples_leaf': 'min_samples_leaf', \n",
    "                   'param_min_samples_split': 'min_samples_split', \n",
    "                   'mean_test_roc_auc': 'roc_auc', \n",
    "                   'mean_test_accuracy': 'accuracy', \n",
    "                   'mean_train_neg_log_loss': 'neg_log_loss'}\n",
    "    results = pd.DataFrame(cv_object.cv_results_)\n",
    "    results.rename(columns=rename_cols, inplace=True)\n",
    "    results = results[['max_depth', 'max_features', 'min_samples_leaf', 'min_samples_split', \n",
    "                       'roc_auc', 'accuracy', 'neg_log_loss']]\n",
    "    return results.sort_values(by='roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_search_cv(rf_gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print rf_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retrain with best params on 100 trees (NEED TO RETRAIN)\n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year', \n",
    "                'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero',\n",
    "                  'last_10_appeal_grant_by_judge': 'median', 'last_10_appeal_grant_by_judge_nat': 'median',\n",
    "                  'original_dec_type_string': 'none', 'original_dec_string': 'none'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=100, min_samples_split=5, max_features='sqrt', \n",
    "                                max_depth=80, min_samples_leaf=1, random_state=44))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_model_data(df, label='granted', cat_features = CAT_FEATURES, \n",
    "                                                  num_features = NUM_FEATURES, impute_methods = IMPUTE_METHODS) \n",
    "rf_best_model, rf_best_metrics, rf_best_fi, rf_best_cfi, rf_best_truth, rf_best_pred = train_model(\n",
    "    MODEL, X_train, y_train, X_test, y_test, print_metrics=True, print_charts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo_comparison_tuned = {'Random Forest (Tuned)': rf_best_metrics,\n",
    "                         'Random Forest': rf_metrics} \n",
    "\n",
    "pd.DataFrame.from_dict(algo_comparison_tuned, orient='index').sort_values(by='ROC AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check feature importances \n",
    "rf_best_fi.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check collapsed feature importances \n",
    "rf_best_cfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save model to pickle \n",
    "import pickle\n",
    "model_pkl_fname = \"aggregate_random_forest_v0.pkl\"\n",
    "#model_pkl_fname = os.path.join(DATAFOLDER, 'aggregate_random_forest_v0.pkl') # why doesn't this work?\n",
    "with open(model_pkl_fname, 'wb') as file:  \n",
    "    pickle.dump(rf_best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability calibration can sometimes be an issue for random forest. But it appears that our classifier is already well-calibrated, so we deem it unnecessary to proceed with calibration methods like Platt Scaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve \n",
    "y_pred_outofbox = rf_model.predict_proba(X_test)[:,1]\n",
    "y_pred_best = rf_best_model.predict_proba(X_test)[:,1]\n",
    "calibration_outofbox = calibration_curve(y_test, y_pred_outofbox, n_bins=10)\n",
    "calibration_best = calibration_curve(y_test, y_pred_best, n_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(calibration_outofbox[0], calibration_outofbox[1], label='Random Forest')\n",
    "plt.plot(calibration_best[0], calibration_best[1], label='Random Forest (Tuned)')\n",
    "plt.plot(np.arange(0, 1.1, 0.1), np.arange(0, 1.1, 0.1), label='Perfectly Calibrated', color='grey')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Dependence Plots (To Fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pdpbox import pdp\n",
    "\n",
    "def pdp_plot(model, X_train, feature, feature_is_cat=False, isolate_samples=1000, plot_samples=200): \n",
    "    \"\"\"\n",
    "    Uses pdpbox package to plot partial dependence plot. Accepts trained classifier (model), X_train, \n",
    "    and feature name as inputs. Feature chosen may be categorical, in which case the function will retrieve \n",
    "    all the corresponding dummy variables. \n",
    "    \"\"\" \n",
    "    \n",
    "    # if feature is categorical, generate list of dummy variable names, else use feature name \n",
    "    if feature_is_cat: \n",
    "        plot_feature = [x for x in X_train.columns if feature + ':::' in x]\n",
    "    else: \n",
    "        plot_feature = feature \n",
    "\n",
    "    # use pdpbox methods \n",
    "    pdp_isolate = pdp.pdp_isolate(model, X_train.sample(n=isolate_samples), plot_feature)\n",
    "    pdp.pdp_plot(pdp_isolate, feature, plot_org_pts=True, plot_lines=True, center=False, frac_to_plot=plot_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pdp_plot(rf_best_model, X_train, 'datAppealFiled_year', feature_is_cat=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pdp_plot(rf_model, X_train, 'strCustody', feature_is_cat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdp_plot(rf_model, X_train, 'case_type_string', feature_is_cat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdp_plot(rf_model, X_train, 'nat_string_grouped', feature_is_cat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdp_plot(rf_model, X_train, 'ij_code_grouped', feature_is_cat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far we aggregated data across time as a single population from which we drew train and test samples from. This might not be the most realistic way to build a model that is used to predict future appeal outcomes (i.e. we do not have the luxury of using data from future appeals to inform the outcome of a current appeal). To more realistically assess the power of our predictive models, we will build a sequence of models: one model to predict each year's of appeals (by datAppealFiled_year) between 1991 and 2013 using data in preceeding years. In other words, we will only use data from 2000 and earlier to predict 2001's appeals, data from 2001 and earlier to predict 2002's appeals etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_data_by_year(df, appeals_df, label, unique_id, cat_features, num_features, impute_methods, predict_year): \n",
    "    \"\"\" Generates features on data for years prior to predict_year \"\"\"\n",
    "\n",
    "    # add 'datAppealFiled_year' if not in num_features \n",
    "    if 'datAppealFiled_year' not in num_features: \n",
    "        num_features_ = num_features + ['datAppealFiled_year'] \n",
    "    else: \n",
    "        num_features_ = num_features \n",
    "\n",
    "    # subsets features we are interested in \n",
    "    cat_feature_values = dict([(f, [str(x) for x in df[f].dropna().unique().tolist()]) for f in cat_features]) \n",
    "    data = df.set_index(unique_id)\n",
    "    if label is not None: \n",
    "        data = data[cat_features + num_features_ + [label]].copy() \n",
    "    else: \n",
    "        data = data[cat_features + num_features].copy()\n",
    "\n",
    "    # train test split \n",
    "    train_data = data[data['datAppealFiled_year'] < predict_year]\n",
    "    test_data = data[data['datAppealFiled_year'] == predict_year]\n",
    "    \n",
    "    # return y=None if label is not passed (used for parsing data for pure predictions)\n",
    "    if label is not None: \n",
    "        x_train, y_train = train_data.drop(label, axis=1).copy(), train_data[label].copy() \n",
    "        x_test, y_test = test_data.drop(label, axis=1).copy(), test_data[label].copy() \n",
    "    else: \n",
    "        x_train, y_train = train_data, None \n",
    "        x_test, y_test = test_data, None \n",
    "\n",
    "    # transform \n",
    "    X_train = transform_features(x_train, appeals_df, cat_features, num_features, impute_methods)\n",
    "    X_test = transform_features(x_test, appeals_df, cat_features, num_features, impute_methods)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def get_model_data_by_year(df, label, cat_features, num_features, impute_methods, predict_year): \n",
    "#     \"\"\" Subsets variables used for model, runs it through pipeline to output data for model \"\"\"\n",
    "    \n",
    "#     # add 'datAppealFiled_year' if not in num_features \n",
    "#     if 'datAppealFiled_year' not in num_features: \n",
    "#         num_features_ = num_features + ['datAppealFiled_year'] \n",
    "#     else: \n",
    "#         num_features_ = num_features \n",
    "    \n",
    "#     # subsets features we are interested in \n",
    "#     cat_feature_values = dict([(f, [str(x) for x in df[f].dropna().unique().tolist()]) for f in cat_features]) \n",
    "#     data = df[cat_features + num_features_ + [label]].copy() \n",
    "    \n",
    "#     # train test split \n",
    "#     train_data = data[data['datAppealFiled_year'] < predict_year]\n",
    "#     test_data = data[data['datAppealFiled_year'] == predict_year]\n",
    "#     x_train, y_train = train_data.drop(label, axis=1).copy(), train_data[label].copy() \n",
    "#     x_test, y_test = test_data.drop(label, axis=1).copy(), test_data[label].copy() \n",
    "    \n",
    "#     # make pipeline \n",
    "#     data_pipeline = Pipeline([\n",
    "#         ('impute', ImputeMissingData(impute_methods, num_features, cat_features)),         \n",
    "#         ('convert_dtypes', ConvertDataTypes(num_features, cat_features)), \n",
    "#         ('dummify', Dummify(cat_feature_values))\n",
    "#     ])\n",
    "    \n",
    "#     # run pipeline \n",
    "#     X_train = data_pipeline.fit_transform(x_train)\n",
    "#     X_test = data_pipeline.transform(x_test)\n",
    "#     print(\"Training Data: {} | Test Data: {}\".format(X_train.shape, X_test.shape)) \n",
    "    \n",
    "#     return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_sequential_models(df, label, cat_features, num_features, impute_methods, \n",
    "                          start_year, end_year, weight_decay=None, print_charts=False, print_metrics=True): \n",
    "    \"\"\" Trains a sequence of models using data from preceeding years to test on current year \n",
    "        TODO: modularize this if have time\"\"\"\n",
    "    \n",
    "    # initialize empty dictionary to collect all results \n",
    "    sequential_results = {}\n",
    "    \n",
    "    # loop through each year to train model on data from preceeding years then test on current year \n",
    "    for year in np.arange(start_year, end_year+1, 1): \n",
    "        print(\"Training model to predict {} appeals...\".format(year)) \n",
    "        result = {} # initialize empty dictionary to collect result for each year \n",
    "        X_train, X_test, y_train, y_test = get_model_data_by_year(\n",
    "            df, df, label='granted', unique_id='idnproceeding', cat_features=cat_features, num_features=num_features, \n",
    "            impute_methods=impute_methods, predict_year=year) \n",
    "        \n",
    "        # weight samples \n",
    "        if weight_decay is not None:\n",
    "            print(weight_decay)\n",
    "            sample_weight = X_train['datAppealFiled_year'].apply(lambda x: weight_decay ** (year-x-1))\n",
    "        else: \n",
    "            sample_weight = None \n",
    "        \n",
    "        # datAppealFiled_year is included in X_train by default; remove if not in num_features\n",
    "        if 'datAppealFiled_year' not in num_features: \n",
    "            X_train = X_train[[c for c in X_train.columns if c != 'datAppealFiled_year']]\n",
    "            X_test = X_test[[c for c in X_train.columns if c != 'datAppealFiled_year']]\n",
    "        else: \n",
    "            pass \n",
    "        \n",
    "        # save results to dictionary \n",
    "        result['model'], result['metrics'], result['fi'], result['cfi'], result['truth'], result['pred'] = train_model(\n",
    "            MODEL, X_train, y_train, X_test, y_test, \n",
    "            print_charts=print_charts, print_metrics=print_metrics, sample_weight=sample_weight) \n",
    "        sequential_results[year] = result \n",
    "        \n",
    "    # summarize model performance metrics \n",
    "    metric_summary = pd.DataFrame.from_dict(sequential_results, orient='index')['metrics'].apply(pd.Series)\n",
    "    print(metric_summary)\n",
    "    print(\"Average model performance metrics:\")\n",
    "    print(metric_summary.mean()) \n",
    "    plot_sequential_performance(metric_summary)\n",
    "    \n",
    "    # average feature importances \n",
    "    average_cfi = pd.DataFrame.from_dict(sequential_results, orient='index')['cfi']\\\n",
    "                              .apply(pd.Series).mean().sort_values(ascending=False)\n",
    "    print(\"Average feature importances:\")\n",
    "    print(average_cfi)     \n",
    "    \n",
    "    return metric_summary, average_cfi, sequential_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sequential_performance(sequential_metrics):\n",
    "    \"\"\" Plots AUC and Accuracy by test year \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(sequential_metrics['ROC AUC'])\n",
    "    plt.plot(sequential_metrics['Accuracy'])\n",
    "    plt.ticklabel_format(useOffset=False)\n",
    "    plt.title('Accuracy and AUC of Sequential Models')\n",
    "    plt.xlabel('Test Year')\n",
    "    plt.legend(loc='best') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that building the model in a sequential way degraded the performance considerably. Perhaps even more surprisingly, accuracy appears to be worse in later years, which is somewhat counterintuitive given that later models had more data to train on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model to predict 1994 appeals...\n",
      "Training Data: (26606, 541) | Test Data: (5015, 541)\n",
      "{'Recall': 0.52772373540856032, 'Log Loss': 0.56791185493086804, 'Precision': 0.69640564826700901, 'ROC AUC': 0.77578042915960421, 'Accuracy': 0.7120638085742772}\n",
      "Training model to predict 1995 appeals...\n",
      "Training Data: (31621, 541) | Test Data: (8197, 541)\n",
      "{'Recall': 0.57111111111111112, 'Log Loss': 0.53330566483029029, 'Precision': 0.58188679245283015, 'ROC AUC': 0.77438468120658399, 'Accuracy': 0.7235573990484323}\n",
      "Training model to predict 1996 appeals...\n",
      "Training Data: (39818, 541) | Test Data: (9956, 541)\n",
      "{'Recall': 0.49374833732375634, 'Log Loss': 0.56623122227879352, 'Precision': 0.71715610510046368, 'ROC AUC': 0.78595028539541256, 'Accuracy': 0.7353354760948172}\n",
      "Training model to predict 1997 appeals...\n",
      "Training Data: (49774, 541) | Test Data: (7896, 541)\n",
      "{'Recall': 0.52910512597741099, 'Log Loss': 0.61303487532708123, 'Precision': 0.63152436916695476, 'ROC AUC': 0.72022511356155983, 'Accuracy': 0.65906788247213777}\n",
      "Training model to predict 1998 appeals...\n",
      "Training Data: (57670, 541) | Test Data: (7735, 541)\n",
      "{'Recall': 0.38724676187313184, 'Log Loss': 0.59165482998870433, 'Precision': 0.63369565217391299, 'ROC AUC': 0.72045851634607616, 'Accuracy': 0.6743374272786038}\n",
      "Training model to predict 1999 appeals...\n",
      "Training Data: (65405, 541) | Test Data: (9515, 541)\n",
      "{'Recall': 0.49593740595847124, 'Log Loss': 0.53536426391794756, 'Precision': 0.68155500413564929, 'ROC AUC': 0.77759142003000004, 'Accuracy': 0.74303730951129798}\n",
      "Training model to predict 2000 appeals...\n",
      "Training Data: (74920, 541) | Test Data: (8952, 541)\n",
      "{'Recall': 0.46791443850267378, 'Log Loss': 0.49027045097553879, 'Precision': 0.66539923954372626, 'ROC AUC': 0.77955764215724455, 'Accuracy': 0.77558087578194812}\n",
      "Training model to predict 2001 appeals...\n",
      "Training Data: (83872, 541) | Test Data: (8895, 541)\n",
      "{'Recall': 0.26318359375, 'Log Loss': 0.46594214362108066, 'Precision': 0.59822419533851279, 'ROC AUC': 0.74931115046964003, 'Accuracy': 0.78965711073636879}\n",
      "Training model to predict 2002 appeals...\n",
      "Training Data: (92767, 541) | Test Data: (13529, 541)\n",
      "{'Recall': 0.16143497757847533, 'Log Loss': 0.49474395075160199, 'Precision': 0.53617021276595744, 'ROC AUC': 0.70784026077160522, 'Accuracy': 0.77426269495158551}\n",
      "Training model to predict 2003 appeals...\n",
      "Training Data: (106296, 541) | Test Data: (16090, 541)\n",
      "{'Recall': 0.16142311084975008, 'Log Loss': 0.46613771112936725, 'Precision': 0.5304347826086957, 'ROC AUC': 0.73179438098537575, 'Accuracy': 0.79254195152268492}\n",
      "Training model to predict 2004 appeals...\n",
      "Training Data: (122386, 541) | Test Data: (15408, 541)\n",
      "{'Recall': 0.11035607502038597, 'Log Loss': 0.52316866518397442, 'Precision': 0.63836477987421381, 'ROC AUC': 0.7213341519781088, 'Accuracy': 0.77265057113187952}\n",
      "Training model to predict 2005 appeals...\n",
      "Training Data: (137794, 541) | Test Data: (15627, 541)\n",
      "{'Recall': 0.18561584840654607, 'Log Loss': 0.5660429015537648, 'Precision': 0.65204236006051441, 'ROC AUC': 0.72867930808108961, 'Accuracy': 0.72854674601650993}\n",
      "Training model to predict 2006 appeals...\n",
      "Training Data: (153421, 541) | Test Data: (14992, 541)\n",
      "{'Recall': 0.30329289428076256, 'Log Loss': 0.54876238867069727, 'Precision': 0.62166962699822381, 'ROC AUC': 0.73149815006033125, 'Accuracy': 0.72865528281750269}\n",
      "Training model to predict 2007 appeals...\n",
      "Training Data: (168413, 541) | Test Data: (14317, 541)\n",
      "{'Recall': 0.31590156176053003, 'Log Loss': 0.54010674009930171, 'Precision': 0.59491978609625673, 'ROC AUC': 0.72631107325608601, 'Accuracy': 0.73458126702521476}\n",
      "Training model to predict 2008 appeals...\n",
      "Training Data: (182730, 541) | Test Data: (12896, 541)\n",
      "{'Recall': 0.26173197871311077, 'Log Loss': 0.56155013993029601, 'Precision': 0.6852438252058265, 'ROC AUC': 0.71741785431151606, 'Accuracy': 0.72479838709677424}\n",
      "Training model to predict 2009 appeals...\n",
      "Training Data: (195626, 541) | Test Data: (11458, 541)\n",
      "{'Recall': 0.22611607142857143, 'Log Loss': 0.71477433146078861, 'Precision': 0.64769820971867009, 'ROC AUC': 0.63200453977807802, 'Accuracy': 0.64932798045034035}\n",
      "Training model to predict 2010 appeals...\n",
      "Training Data: (207084, 541) | Test Data: (10215, 541)\n",
      "{'Recall': 0.3614519427402863, 'Log Loss': 0.60007236468509118, 'Precision': 0.64243525670149937, 'ROC AUC': 0.70270150027561762, 'Accuracy': 0.67841409691629961}\n",
      "Training model to predict 2011 appeals...\n",
      "Training Data: (217299, 541) | Test Data: (10819, 541)\n",
      "{'Recall': 0.38595085470085472, 'Log Loss': 0.57643216105711159, 'Precision': 0.62043795620437958, 'ROC AUC': 0.71953640784029482, 'Accuracy': 0.70579536001478882}\n",
      "Training model to predict 2012 appeals...\n",
      "Training Data: (228118, 541) | Test Data: (8926, 541)\n",
      "{'Recall': 0.40105622864243556, 'Log Loss': 0.57029149636211662, 'Precision': 0.64906988436400204, 'ROC AUC': 0.74084893156450771, 'Accuracy': 0.70580327134214649}\n",
      "Training model to predict 2013 appeals...\n",
      "Training Data: (237044, 541) | Test Data: (5125, 541)\n",
      "{'Recall': 0.51816443594646266, 'Log Loss': 0.61781090765392388, 'Precision': 0.75194228634850169, 'ROC AUC': 0.75988489636101852, 'Accuracy': 0.66692682926829272}\n",
      "      Accuracy  Log Loss  Precision   ROC AUC    Recall\n",
      "1994  0.712064  0.567912   0.696406  0.775780  0.527724\n",
      "1995  0.723557  0.533306   0.581887  0.774385  0.571111\n",
      "1996  0.735335  0.566231   0.717156  0.785950  0.493748\n",
      "1997  0.659068  0.613035   0.631524  0.720225  0.529105\n",
      "1998  0.674337  0.591655   0.633696  0.720459  0.387247\n",
      "1999  0.743037  0.535364   0.681555  0.777591  0.495937\n",
      "2000  0.775581  0.490270   0.665399  0.779558  0.467914\n",
      "2001  0.789657  0.465942   0.598224  0.749311  0.263184\n",
      "2002  0.774263  0.494744   0.536170  0.707840  0.161435\n",
      "2003  0.792542  0.466138   0.530435  0.731794  0.161423\n",
      "2004  0.772651  0.523169   0.638365  0.721334  0.110356\n",
      "2005  0.728547  0.566043   0.652042  0.728679  0.185616\n",
      "2006  0.728655  0.548762   0.621670  0.731498  0.303293\n",
      "2007  0.734581  0.540107   0.594920  0.726311  0.315902\n",
      "2008  0.724798  0.561550   0.685244  0.717418  0.261732\n",
      "2009  0.649328  0.714774   0.647698  0.632005  0.226116\n",
      "2010  0.678414  0.600072   0.642435  0.702702  0.361452\n",
      "2011  0.705795  0.576432   0.620438  0.719536  0.385951\n",
      "2012  0.705803  0.570291   0.649070  0.740849  0.401056\n",
      "2013  0.666927  0.617811   0.751942  0.759885  0.518164\n",
      "Average model performance metrics:\n",
      "Accuracy     0.723747\n",
      "Log Loss     0.557180\n",
      "Precision    0.638814\n",
      "ROC AUC      0.735156\n",
      "Recall       0.356423\n",
      "dtype: float64\n",
      "Average feature importances:\n",
      "ij_code_grouped                      0.262796\n",
      "nat_grouped                          0.238929\n",
      "datAppealFiled_year                  0.085940\n",
      "comp_year                            0.060690\n",
      "osc_year                             0.058718\n",
      "input_year                           0.056147\n",
      "last_10_appeal_grant_by_judge        0.056000\n",
      "last_10_appeal_grant_by_judge_nat    0.051531\n",
      "original_dec_string                  0.036676\n",
      "strCustody                           0.033785\n",
      "case_type_string                     0.018739\n",
      "lawyer                               0.015133\n",
      "original_dec_type_string             0.008273\n",
      "affirmative                          0.005011\n",
      "defensive                            0.004899\n",
      "oral                                 0.003488\n",
      "written                              0.002952\n",
      "strProbono                           0.000294\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAEZCAYAAADbmSJHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a156591d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test with same variables as rf_best\n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year', \n",
    "                'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero',\n",
    "                  'last_10_appeal_grant_by_judge': 'median', 'last_10_appeal_grant_by_judge_nat': 'median',\n",
    "                  'original_dec_type_string': 'none', 'original_dec_string': 'none'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=100, min_samples_split=5, max_features='sqrt', \n",
    "                                max_depth=80, min_samples_leaf=1, random_state=44))\n",
    "\n",
    "sequential_metrics, average_cfi, sequential_results = fit_sequential_models(\n",
    "    df, 'granted', cat_features=CAT_FEATURES, num_features=NUM_FEATURES, impute_methods=IMPUTE_METHODS, \n",
    "    start_year=1994, end_year=2013, print_charts=False, print_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying weight decay to samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One reason could be that there are periodic shifts in sentiment such that older data might be less informative to newer cases. Let's attempt to weight recent samples more than older samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rf_best + weight decay 0.7 (AUC & Accuracy both up slightly by 0.002)\n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year', \n",
    "                'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero',\n",
    "                  'last_10_appeal_grant_by_judge': 'median', 'last_10_appeal_grant_by_judge_nat': 'median',\n",
    "                  'original_dec_type_string': 'none', 'original_dec_string': 'none'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=100, min_samples_split=5, max_features='sqrt', \n",
    "                                max_depth=80, min_samples_leaf=1, random_state=44))\n",
    "\n",
    "sequential_metrics, average_cfi, sequential_results = fit_sequential_models(\n",
    "    df, 'granted', cat_features=CAT_FEATURES, num_features=NUM_FEATURES, impute_methods=IMPUTE_METHODS, \n",
    "    start_year=1994, end_year=2013, weight_decay=0.7, print_charts=False, print_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tune weight decay \n",
    "\n",
    "def tune_weight_decay(df, label, cat_features, num_features, impute_methods, start_year, end_year, weight_decay_alphas):\n",
    "    results = [] \n",
    "    for alpha in weight_decay_alphas: \n",
    "        result = {} \n",
    "        metrics_summary, _, _ = fit_sequential_models(\n",
    "            df, 'granted', cat_features=CAT_FEATURES, num_features=NUM_FEATURES, impute_methods=IMPUTE_METHODS, \n",
    "            start_year=start_year, end_year=end_year, weight_decay=alpha, print_metrics=False, print_charts=False)\n",
    "        result['alpha'] = alpha \n",
    "        result['average_accuracy'] = metrics_summary['Accuracy'].mean() \n",
    "        result['average_roc_auc'] = metrics_summary['ROC AUC'].mean() \n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find best alpha\n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year', \n",
    "                'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero',\n",
    "                  'last_10_appeal_grant_by_judge': 'median', 'last_10_appeal_grant_by_judge_nat': 'median',\n",
    "                  'original_dec_type_string': 'none', 'original_dec_string': 'none'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, min_samples_split=5, max_features='sqrt', \n",
    "                                max_depth=80, min_samples_leaf=1, random_state=44))\n",
    "\n",
    "weight_decay_tuning = tune_weight_decay(df, 'granted', cat_features=CAT_FEATURES, num_features=NUM_FEATURES, \n",
    "                                        impute_methods=IMPUTE_METHODS, start_year=1994, end_year=2013, \n",
    "                                        weight_decay_alphas=[.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0])\n",
    "weight_decay_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model to predict 1994 appeals...\n",
      "0.5\n",
      "{'Recall': 0.51215953307392992, 'Log Loss': 0.80410227446233296, 'Precision': 0.66942148760330578, 'ROC AUC': 0.76118816760315766, 'Accuracy': 0.6963110667996012}\n",
      "Training model to predict 1995 appeals...\n",
      "0.5\n",
      "{'Recall': 0.5344444444444445, 'Log Loss': 0.64148560706071289, 'Precision': 0.60834738617200679, 'ROC AUC': 0.76494363929146536, 'Accuracy': 0.73331706721971457}\n",
      "Training model to predict 1996 appeals...\n",
      "0.5\n",
      "{'Recall': 0.47778664538441074, 'Log Loss': 0.8653845424440163, 'Precision': 0.72041716807059764, 'ROC AUC': 0.77111677710679027, 'Accuracy': 0.73282442748091603}\n",
      "Training model to predict 1997 appeals...\n",
      "0.5\n",
      "{'Recall': 0.52649869678540395, 'Log Loss': 0.79121128613888292, 'Precision': 0.60640426951300863, 'ROC AUC': 0.69980964925677303, 'Accuracy': 0.64349037487335359}\n",
      "Training model to predict 1998 appeals...\n",
      "0.5\n",
      "{'Recall': 0.41414812354699437, 'Log Loss': 0.70744276513737736, 'Precision': 0.60740379931807109, 'ROC AUC': 0.69866691169915784, 'Accuracy': 0.66774402068519711}\n",
      "Training model to predict 1999 appeals...\n",
      "0.5\n",
      "{'Recall': 0.52091483599157384, 'Log Loss': 0.58826936039065281, 'Precision': 0.60187760778859523, 'ROC AUC': 0.74534611073397294, 'Accuracy': 0.712348922753547}\n",
      "Training model to predict 2000 appeals...\n",
      "0.5\n",
      "{'Recall': 0.45492742551566079, 'Log Loss': 0.61375470875560856, 'Precision': 0.627172195892575, 'ROC AUC': 0.7617231739266882, 'Accuracy': 0.76150580875781948}\n",
      "Training model to predict 2001 appeals...\n",
      "0.5\n",
      "{'Recall': 0.30029296875, 'Log Loss': 0.61293110421116392, 'Precision': 0.54328621908127206, 'ROC AUC': 0.72477924296224616, 'Accuracy': 0.7807757166947723}\n",
      "Training model to predict 2002 appeals...\n",
      "0.5\n",
      "{'Recall': 0.18193465727098015, 'Log Loss': 0.65801215863009765, 'Precision': 0.47254575707154745, 'ROC AUC': 0.66579906332448713, 'Accuracy': 0.76435804567965115}\n",
      "Training model to predict 2003 appeals...\n",
      "0.5\n",
      "{'Recall': 0.19905910026462806, 'Log Loss': 0.65807920271899722, 'Precision': 0.47542134831460675, 'ROC AUC': 0.69929615116237542, 'Accuracy': 0.78427594779366061}\n",
      "Training model to predict 2004 appeals...\n",
      "0.5\n",
      "{'Recall': 0.14623539005164446, 'Log Loss': 0.86246095980343707, 'Precision': 0.56631578947368422, 'ROC AUC': 0.69917266790002575, 'Accuracy': 0.76940550363447557}\n",
      "Training model to predict 2005 appeals...\n",
      "0.5\n",
      "{'Recall': 0.20478036175710596, 'Log Loss': 0.76233117582307519, 'Precision': 0.60805626598465479, 'ROC AUC': 0.70291609544874101, 'Accuracy': 0.72445127023740963}\n",
      "Training model to predict 2006 appeals...\n",
      "0.5\n",
      "{'Recall': 0.36330155979202772, 'Log Loss': 0.70447436699000099, 'Precision': 0.55695782132182003, 'ROC AUC': 0.71043859212500782, 'Accuracy': 0.71498132337246534}\n",
      "Training model to predict 2007 appeals...\n",
      "0.5\n",
      "{'Recall': 0.34973970657832465, 'Log Loss': 0.63776783058939579, 'Precision': 0.55252336448598127, 'ROC AUC': 0.7057991046268357, 'Accuracy': 0.72445344695117697}\n",
      "Training model to predict 2008 appeals...\n",
      "0.5\n",
      "{'Recall': 0.28301886792452829, 'Log Loss': 0.70437849957386445, 'Precision': 0.60340381640020624, 'ROC AUC': 0.69198921277579972, 'Accuracy': 0.71053039702233256}\n",
      "Training model to predict 2009 appeals...\n",
      "0.5\n",
      "{'Recall': 0.25758928571428569, 'Log Loss': 1.1666440108437877, 'Precision': 0.60768825697735651, 'ROC AUC': 0.61291122545858412, 'Accuracy': 0.64470239134229357}\n",
      "Training model to predict 2010 appeals...\n",
      "0.5\n",
      "{'Recall': 0.41896728016359919, 'Log Loss': 0.6714561944469567, 'Precision': 0.57488600491055775, 'ROC AUC': 0.68223381877101397, 'Accuracy': 0.65883504650024471}\n",
      "Training model to predict 2011 appeals...\n",
      "0.5\n",
      "{'Recall': 0.43215811965811968, 'Log Loss': 0.69287201193433023, 'Precision': 0.5689170182841069, 'ROC AUC': 0.70547780571411312, 'Accuracy': 0.69017469267030229}\n",
      "Training model to predict 2012 appeals...\n",
      "0.5\n",
      "{'Recall': 0.42155949052500774, 'Log Loss': 0.73500918713085472, 'Precision': 0.63116279069767445, 'ROC AUC': 0.71557566279112128, 'Accuracy': 0.70255433564866676}\n",
      "Training model to predict 2013 appeals...\n",
      "0.5\n",
      "{'Recall': 0.52122370936902485, 'Log Loss': 0.72874052999963379, 'Precision': 0.73161567364465918, 'ROC AUC': 0.73751456887554945, 'Accuracy': 0.65814634146341466}\n",
      "      Accuracy  Log Loss  Precision   ROC AUC    Recall\n",
      "1994  0.696311  0.804102   0.669421  0.761188  0.512160\n",
      "1995  0.733317  0.641486   0.608347  0.764944  0.534444\n",
      "1996  0.732824  0.865385   0.720417  0.771117  0.477787\n",
      "1997  0.643490  0.791211   0.606404  0.699810  0.526499\n",
      "1998  0.667744  0.707443   0.607404  0.698667  0.414148\n",
      "1999  0.712349  0.588269   0.601878  0.745346  0.520915\n",
      "2000  0.761506  0.613755   0.627172  0.761723  0.454927\n",
      "2001  0.780776  0.612931   0.543286  0.724779  0.300293\n",
      "2002  0.764358  0.658012   0.472546  0.665799  0.181935\n",
      "2003  0.784276  0.658079   0.475421  0.699296  0.199059\n",
      "2004  0.769406  0.862461   0.566316  0.699173  0.146235\n",
      "2005  0.724451  0.762331   0.608056  0.702916  0.204780\n",
      "2006  0.714981  0.704474   0.556958  0.710439  0.363302\n",
      "2007  0.724453  0.637768   0.552523  0.705799  0.349740\n",
      "2008  0.710530  0.704378   0.603404  0.691989  0.283019\n",
      "2009  0.644702  1.166644   0.607688  0.612911  0.257589\n",
      "2010  0.658835  0.671456   0.574886  0.682234  0.418967\n",
      "2011  0.690175  0.692872   0.568917  0.705478  0.432158\n",
      "2012  0.702554  0.735009   0.631163  0.715576  0.421559\n",
      "2013  0.658146  0.728741   0.731616  0.737515  0.521224\n",
      "Average model performance metrics:\n",
      "Accuracy     0.713759\n",
      "Log Loss     0.730340\n",
      "Precision    0.596691\n",
      "ROC AUC      0.712835\n",
      "Recall       0.376037\n",
      "dtype: float64\n",
      "Average feature importances:\n",
      "ij_code_grouped                      0.304112\n",
      "nat_grouped                          0.233069\n",
      "last_10_appeal_grant_by_judge        0.061770\n",
      "last_10_appeal_grant_by_judge_nat    0.060742\n",
      "input_year                           0.057660\n",
      "comp_year                            0.057470\n",
      "osc_year                             0.055164\n",
      "datAppealFiled_year                  0.042450\n",
      "original_dec_string                  0.036514\n",
      "strCustody                           0.029952\n",
      "case_type_string                     0.016243\n",
      "lawyer                               0.012587\n",
      "original_dec_type_string             0.008439\n",
      "defensive                            0.008089\n",
      "affirmative                          0.007981\n",
      "oral                                 0.003603\n",
      "written                              0.003506\n",
      "strProbono                           0.000648\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAEZCAYAAADbmSJHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiISov8HNY2IVSnrBGEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1507c450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# re-run on best weight decay of 0.5\n",
    "CAT_FEATURES = ['nat_grouped', 'ij_code_grouped', 'case_type_string', 'strCustody', 'strProbono', \n",
    "                'original_dec_type_string', 'original_dec_string']\n",
    "NUM_FEATURES = ['datAppealFiled_year', 'lawyer', 'defensive', 'affirmative', 'oral', 'written',\n",
    "                'comp_year', 'osc_year', 'input_year', \n",
    "                'last_10_appeal_grant_by_judge', 'last_10_appeal_grant_by_judge_nat']\n",
    "IMPUTE_METHODS = {'nat_grouped': 'none', 'strCustody': 'none', 'strProbono': 'none', 'case_type_string': 'none', \n",
    "                  'defensive': 'zero', 'affirmative': 'zero', 'oral': 'zero', 'written': 'zero', 'input_year': 'zero',\n",
    "                  'last_10_appeal_grant_by_judge': 'median', 'last_10_appeal_grant_by_judge_nat': 'median',\n",
    "                  'original_dec_type_string': 'none', 'original_dec_string': 'none'}\n",
    "MODEL = (RandomForestClassifier(n_estimators=10, min_samples_split=5, max_features='sqrt', \n",
    "                                max_depth=80, min_samples_leaf=1, random_state=44))\n",
    "\n",
    "sequential_metrics_wt, average_cfi_wt, sequential_results_wt = fit_sequential_models(\n",
    "    df, 'granted', cat_features=CAT_FEATURES, num_features=NUM_FEATURES, impute_methods=IMPUTE_METHODS, \n",
    "    start_year=1994, end_year=2013, weight_decay=0.5, print_charts=False, print_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save sequential models as a tuple to pickle \n",
    "import pickle\n",
    "seq_model_pkl_fname = \"sequential_random_forest_v0.pkl\"\n",
    "models_object = tuple([sequential_results_wt[year]['model'] for year in sequential_results.keys()]) \n",
    "with open(seq_model_pkl_fname, \"wb\") as f:\n",
    "    pickle.dump(models_object, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
